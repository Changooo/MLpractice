layer를 정의하려면 layer가 받는 input의 크기를 알아야한다.

input자체의 크기를 X라고 했을 때, 여러 input(한 batch)을 한 번에 학습시킬 수 있기 때문에
input크기는 X\*batch_size다. (참고: 한 batch가 학습된 것을 한 epoch라고 함)

X는 이미지의 경우 width\*height, vector의 경우 dim, 자연어의 경우 dim(단어)\*length(단어개수)등등
다양한 크기를 가질 수 있다.


vector = 1D tensor
2D tensor = matrix









---------------------------------------------------------------------------
numpy library
array <- np.array([])
array=텐서, []->vector, [[],[]]->matrix, [[[], []],[[], []]]->3D tensor
ndim=몇 D 텐서인지
shape=(dim*dim*dim*...*dim) //dim의 개수는 D개
왼쪽일수록 바깥쪽 dim, 오른쪽일수록 안쪽 dim. (ex) [[[]],[[]]] =>(2, 1, 0)


pytorch library
array <-torch.FloatTensor([])
dim=numpy의 ndim
shape=size()=numpy의 shape

1. torch의 slicer [:, :, ..., :] //:의 개수는 최대 D개
shape=(dim*dim*dim*...*dim)에서 각 dim을 slicing할 수 있다.


2. torch의 브로드캐스팅: 덧셈뺄셈곱셈시 자동으로 피연산자끼리의 크기 맞춤
(1,2) + (2,1) => (2,2) + (2,2)

3. torch의 matrix product
t1.matmul(t2)

4. torch의 mean
shape=(dim*dim*dim*...*dim)에서 각 dim의 mean을 구한다.
t.mean(dim=0): (2,2)->(1,2)
t.mean(dim=1): (2,2)->(2,1)

5. torch의 sum
mean과 동일

6. torch의 max, argmax
mean과 동일, 다만 argmax도 함께 return
 
view, squeeze, unsqueeze, float, long

torch.cat, torch.stack
torch.ones_like, torch.zeros_like




 